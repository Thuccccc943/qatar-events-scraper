{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0267fc7c-aad3-4966-8d51-e8f7bf95867b",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9ee264-1d23-410e-9d31-92fcfdad800f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a430a7dd",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cc5a625-ea87-4e22-8eff-12e428bbf57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapers.iloveqatar import ILoveQatarScraper\n",
    "from scrapers.visitqatar import VisitQatarScraper\n",
    "from scrapers.qatarmuseums import QatarMuseumsScraper\n",
    "from models import Event\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfcb656-4701-4cdb-ad2a-85119d617382",
   "metadata": {},
   "source": [
    "# Authenticate with Google Sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afe61ec8-eb98-4216-b26e-3acd4aa457d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "\n",
    "scope = [\"https://spreadsheets.google.com/feeds\", \"https://www.googleapis.com/auth/drive\"]\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name(\"credentials.json\", scope)\n",
    "client = gspread.authorize(creds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac13271b-508c-4d44-ba5f-c2a9f17eb9ce",
   "metadata": {},
   "source": [
    "# Open Sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "289ef481-fa95-477e-80e4-dfb70b1129a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the spreadsheet by name\n",
    "spreadsheet = client.open(\"EventScrapes\")\n",
    "\n",
    "# Access or create worksheets for each source\n",
    "worksheet_names = [\"ILoveQatar\", \"VisitQatar\", \"QatarMuseums\"]\n",
    "worksheets = {}\n",
    "\n",
    "for name in worksheet_names:\n",
    "    try:\n",
    "        worksheets[name] = spreadsheet.worksheet(name)\n",
    "    except gspread.exceptions.WorksheetNotFound:\n",
    "        worksheets[name] = spreadsheet.add_worksheet(title=name, rows=\"1000\", cols=\"20\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466ec41c-4675-4827-adef-9707466c8888",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "763b66c3-700c-4a0b-bb57-b600595bb393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose which scrapers to run\n",
    "# You can remove a scraper by prefixing it with #, eg #ILoveQatarScraper(),\n",
    "scrapers = [\n",
    "    ILoveQatarScraper(2),\n",
    "    VisitQatarScraper(),\n",
    "    QatarMuseumsScraper(2),\n",
    "]\n",
    "\n",
    "# Allows you to save results for each source as well\n",
    "save_individual_results = False\n",
    "save_to_google_sheets = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c32d94a-b8fe-4432-b632-05072cc447c6",
   "metadata": {},
   "source": [
    "# Initialize functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5816a3b5-85e7-44ff-9fa4-7a36838c4522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_scrapers(scrapers: list) -> List[Event]:\n",
    "    all_events = []\n",
    "    for scraper in scrapers:\n",
    "        try:\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"Running {scraper.source_name} scraper...\")\n",
    "            events = scraper.scrape_events()\n",
    "            if save_to_google_sheets:\n",
    "                events_df = pd.DataFrame([event.to_dict() for event in events])\n",
    "                worksheet = worksheets[scraper.source_name]\n",
    "                append_new_events_to_sheet(events_df, worksheet)\n",
    "            all_events.extend(events)\n",
    "            print(f\"Found {len(events)} events from {scraper.source_name}\")\n",
    "            \n",
    "            # Save individual scraper results\n",
    "            if save_individual_results:\n",
    "                scraper.save_to_csv(events)\n",
    "        except Exception as e:\n",
    "            print(f\"Error with {scraper.source_name} scraper: {e}\")\n",
    "    \n",
    "    return all_events\n",
    "\n",
    "def append_new_events_to_sheet(events_df, worksheet):\n",
    "    # Sanitize any list-type values (Google Sheets does not support lists)\n",
    "    def sanitize(value):\n",
    "        if isinstance(value, list):\n",
    "            return \", \".join(str(v) for v in value)\n",
    "        return value\n",
    "\n",
    "    events_df = events_df.copy()\n",
    "    events_df[\"unique_key\"] = events_df[\"title\"] + events_df[\"start_date\"] + events_df[\"location\"]\n",
    "    sanitized_df = events_df.applymap(sanitize)\n",
    "\n",
    "    # Get existing records to detect duplicates\n",
    "    existing_records = worksheet.get_all_records()\n",
    "    if existing_records:\n",
    "        existing_df = pd.DataFrame(existing_records)\n",
    "        existing_df[\"unique_key\"] = existing_df[\"title\"] + existing_df[\"start_date\"] + existing_df[\"location\"]\n",
    "        new_events_df = sanitized_df[~sanitized_df[\"unique_key\"].isin(existing_df[\"unique_key\"])]\n",
    "    else:\n",
    "        new_events_df = sanitized_df\n",
    "        # Also write headers if sheet is empty\n",
    "        worksheet.update([list(events_df.columns[:-1])], range_name=\"A1\")\n",
    "\n",
    "    if new_events_df.empty:\n",
    "        print(f\"No new events to add to {worksheet.title}.\")\n",
    "        return\n",
    "\n",
    "    # Insert new rows at the top (after headers)\n",
    "    insert_rows = new_events_df.drop(columns=[\"unique_key\"]).values.tolist()\n",
    "    ##### Batch the updates #####\n",
    "    existing = worksheet.get_all_values()\n",
    "    num_new = len(insert_rows)\n",
    "    \n",
    "    # Build the new values (headers + new + existing)\n",
    "    new_values = [existing[0]] if existing else [list(events_df.columns[:-1])]\n",
    "    new_values += insert_rows\n",
    "    if existing:\n",
    "        new_values += existing[1:]\n",
    "    \n",
    "    # Overwrite the entire sheet in one write\n",
    "    worksheet.update(new_values)\n",
    "    print(f\"Inserted {num_new} new events into {worksheet.title}.\")\n",
    "\n",
    "\n",
    "    print(f\"Inserted {len(insert_rows)} new events into {worksheet.title}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c901154-4d96-4aac-ac8f-34f942707920",
   "metadata": {},
   "source": [
    "# Run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0cbd3f0-c599-4644-b65f-d5bbf8977d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Running ILoveQatar scraper...\n",
      "Scraping page 1...\n",
      "Scraping page 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_271616/1349727239.py:32: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  sanitized_df = events_df.applymap(sanitize)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 10 new events into ILoveQatar.\n",
      "Inserted 10 new events into ILoveQatar.\n",
      "Found 20 events from ILoveQatar\n",
      "\n",
      "==================================================\n",
      "Running VisitQatar scraper...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_271616/1349727239.py:32: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  sanitized_df = events_df.applymap(sanitize)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new events to add to VisitQatar.\n",
      "Found 74 events from VisitQatar\n",
      "\n",
      "==================================================\n",
      "Running QatarMuseums scraper...\n",
      "Scraping page 1...\n",
      "Scraping page 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_271616/1349727239.py:32: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  sanitized_df = events_df.applymap(sanitize)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 11 new events into QatarMuseums.\n",
      "Inserted 11 new events into QatarMuseums.\n",
      "Found 26 events from QatarMuseums\n"
     ]
    }
   ],
   "source": [
    "all_events = run_scrapers(scrapers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d310686-d2bc-4d4f-bc91-78d78bcc1b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df = pd.DataFrame([event.to_dict() for event in all_events])\n",
    "events_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67cee9b-76d2-4317-8ab2-21078c83fd0f",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774aeec7-1ff7-43f5-9f9b-60b98ae2ea49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nEvent Statistics:\")\n",
    "print(f\"Total events: {len(all_events)}\")\n",
    "# By source\n",
    "source_counts = events_df['source'].value_counts()\n",
    "print(\"\\nBy source:\")\n",
    "print(source_counts)\n",
    "# By category (if available)\n",
    "if 'category' in events_df.columns:\n",
    "    category_counts = events_df['category'].value_counts()\n",
    "    print(\"\\nBy category:\")\n",
    "    print(category_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dd224a-599c-4110-847e-acaa5901fc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "source_counts.plot(kind='bar', color=['skyblue', 'lightgreen'])\n",
    "plt.title('Number of Events by Source')\n",
    "plt.xlabel('Source')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76563914-acb8-41ee-90dc-1ca722dd0345",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'category' in events_df.columns:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    category_counts.plot(kind='bar', color='lightcoral')\n",
    "    plt.title('Number of Events by Category')\n",
    "    plt.xlabel('Category')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2682f6-6b46-488b-9970-685adc0d3d13",
   "metadata": {},
   "source": [
    "# Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e4b324-9a70-4e55-afc4-c841e98c413a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_filename = \"combined_events.csv\"\n",
    "\n",
    "# Convert events to DataFrame\n",
    "new_combined_df = pd.DataFrame([e.to_dict() for e in all_events])\n",
    "\n",
    "# Append if file exists, avoid duplicates\n",
    "if os.path.exists(combined_filename):\n",
    "    existing_df = pd.read_csv(combined_filename)\n",
    "    combined_df = pd.concat([existing_df, new_combined_df], ignore_index=True)\n",
    "    combined_df.drop_duplicates(subset=[\"title\", \"start_date\", \"location\"], inplace=True)\n",
    "else:\n",
    "    combined_df = new_combined_df\n",
    "\n",
    "combined_df.to_csv(combined_filename, index=False)\n",
    "print(f\"\\nSaved {len(combined_df)} total unique events to {combined_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b78a78-2161-4ea2-ad7d-dcd00bf5dabb",
   "metadata": {},
   "source": [
    "# Raw inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335fcf62-55f2-4c13-bb6d-739c4b5813dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSample Event Details:\")\n",
    "for idx, event in enumerate(all_events[:3], 1):  # Show first 3 events\n",
    "    print(f\"\\nEvent {idx}:\")\n",
    "    print(f\"Title: {event.title}\")\n",
    "    print(f\"Date: {event.start_date} to {event.end_date}\")\n",
    "    print(f\"Time: {event.time}\")\n",
    "    print(f\"Location: {event.location}\")\n",
    "    print(f\"Source: {event.source}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pipenv (Events scraper)",
   "language": "python",
   "name": "events-scraper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
